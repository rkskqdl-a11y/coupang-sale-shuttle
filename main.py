import os
import hmac
import hashlib
import time
import requests
import json
from datetime import datetime
from urllib.parse import urlencode
import random
import re
import google.generativeai as genai

# 1. ì„¤ì • (SITE_URL ëì— /ë¥¼ ë¶™ì´ì§€ ì•ŠëŠ” ê²ƒì´ ê´€ë¡€ì…ë‹ˆë‹¤)
ACCESS_KEY = os.environ.get('COUPANG_ACCESS_KEY')
SECRET_KEY = os.environ.get('COUPANG_SECRET_KEY')
GEMINI_KEY = os.environ.get('GEMINI_API_KEY')
SITE_URL = "https://rkskqdl-a11y.github.io/coupang-sale-shuttle"

if GEMINI_KEY:
    genai.configure(api_key=GEMINI_KEY)

def get_authorization_header(method, path, query_string):
    datetime_gmt = time.strftime('%y%m%dT%H%M%SZ', time.gmtime())
    message = datetime_gmt + method + path + query_string
    signature = hmac.new(bytes(SECRET_KEY, 'utf-8'), msg=bytes(message, 'utf-8'), digestmod=hashlib.sha256).hexdigest()
    return f"CEA algorithm=HmacSHA256, access-key={ACCESS_KEY}, signed-date={datetime_gmt}, signature={signature}"

def fetch_data(keyword):
    try:
        DOMAIN = "https://api-gateway.coupang.com"
        path = "/v2/providers/affiliate_open_api/apis/openapi/v1/products/search"
        params = {"keyword": keyword, "limit": 10}
        query_string = urlencode(params)
        url = f"{DOMAIN}{path}?{query_string}"
        headers = {"Authorization": get_authorization_header("GET", path, query_string), "Content-Type": "application/json"}
        response = requests.get(url, headers=headers, timeout=15)
        data = response.json()
        if 'data' in data and data['data'].get('productData'):
            return data['data']['productData']
        return []
    except: return []

def get_title_from_html(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            match = re.search(r'<title>(.*?)</title>', content)
            if match: return match.group(1)
    except: pass
    return "ì¶”ì²œ ìƒí’ˆ"

def generate_ai_content(product_name):
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = f"ìƒí’ˆëª… '{product_name}'ì— ëŒ€í•´ ì‡¼í•‘ ì „ë¬¸ê°€ì²˜ëŸ¼ ì¹œì ˆí•œ í•´ìš”ì²´ë¡œ 400ì ë‚´ì™¸ ìƒì„¸ ë¦¬ë·°ë¥¼ HTML ì—†ì´ ì‘ì„±í•´ì¤˜. ì¥ì  3ê°€ì§€ í¬í•¨."
        response = model.generate_content(prompt)
        return response.text.replace("\n", "<br>")
    except:
        return f"{product_name}ì€ í’ˆì§ˆê³¼ ê°€ê²© ëª¨ë‘ ì¡ì€ ìµœê³ ì˜ ì„ íƒì…ë‹ˆë‹¤."

def main():
    os.makedirs("posts", exist_ok=True)
    
    # ğŸ’ í•˜ë£¨ 4íšŒ ì‹¤í–‰ ì¤‘ 1íšŒì°¨(10ê°œ) ì²˜ë¦¬
    target = f"{random.choice(['ê°€ì„±ë¹„', 'íŠ¹ê°€', 'ì¸ê¸°'])} {random.choice(['ê°€ì „', 'ìƒí•„í’ˆ', 'ì˜ë¥˜'])}"
    print(f"ğŸ” ê²€ìƒ‰ì–´: {target}")
    products = fetch_data(target)
    
    for item in products:
        try:
            p_id = item['productId']
            # ğŸ’ ì´ë¯¸ì§€ URL ë²„ê·¸ ìˆ˜ì •: ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ë¬¸ìì—´ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ ì¶”ì¶œ
            clean_img_url = item['productImage'].split('?')[0]
            
            filename = f"posts/{datetime.now().strftime('%Y%m%d')}_{p_id}.html"
            if os.path.exists(filename): continue 
            
            ai_content = generate_ai_content(item['productName'])
            
            with open(filename, "w", encoding="utf-8") as f:
                f.write(f"""<!DOCTYPE html><html><head><meta charset='UTF-8'><title>{item['productName']}</title></head>
                <body><div style='max-width:600px; margin:auto;'>
                <h2>{item['productName']}</h2>
                <img src='{clean_img_url}' style='width:100%; border-radius:15px;'>
                <div style='background:#f9f9f9; padding:20px; border-radius:10px; margin:20px 0;'>{ai_content}</div>
                <div style='font-size:1.5rem; color:#e44d26; font-weight:bold;'>{format(item['productPrice'], ',')}ì›</div>
                <a href='{item['productUrl']}' style='display:block; background:#e44d26; color:white; padding:15px; text-align:center; text-decoration:none; border-radius:50px; margin-top:20px;'>ğŸ‘‰ ìµœì €ê°€ í™•ì¸í•˜ê¸°</a>
                <p style='font-size:0.8rem; color:#999; margin-top:30px;'>ë³¸ í¬ìŠ¤íŒ…ì€ ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ í™œë™ì˜ ì¼í™˜ìœ¼ë¡œ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
                </div></body></html>""")
            
            time.sleep(35)
        except: continue

    # ğŸ’ ì‚¬ì´íŠ¸ë§µ ë° robots.txt ê°±ì‹  ë¡œì§ (ì‹œì°¨ ë¬¸ì œ í•´ê²°)
    files = sorted([f for f in os.listdir("posts") if f.endswith(".html")], reverse=True)
    
    # Sitemap.xml ìƒì„±
    with open("sitemap.xml", "w", encoding="utf-8") as f:
        f.write('<?xml version="1.0" encoding="UTF-8"?>\n<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n')
        f.write(f'<url><loc>{SITE_URL}/</loc><priority>1.0</priority></url>\n')
        for file in files:
            f.write(f'<url><loc>{SITE_URL}/posts/{file}</loc><priority>0.8</priority></url>\n')
        f.write('</urlset>')

    # robots.txt ìƒì„±
    with open("robots.txt", "w", encoding="utf-8") as f:
        f.write(f"User-agent: *\nAllow: /\nSitemap: {SITE_URL}/sitemap.xml")

    print(f"âœ¨ ì‚¬ì´íŠ¸ë§µ ê°±ì‹  ì™„ë£Œ! ì´ {len(files)}ê°œì˜ ê²½ë¡œê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
