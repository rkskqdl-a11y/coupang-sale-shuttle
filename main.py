import os, hmac, hashlib, time, requests, json, random, re
from datetime import datetime
from urllib.parse import quote

# [1. ì„¤ì • ì •ë³´]
ACCESS_KEY = os.environ.get('COUPANG_ACCESS_KEY', '').strip()
SECRET_KEY = os.environ.get('COUPANG_SECRET_KEY', '').strip()
GEMINI_KEY = os.environ.get('GEMINI_API_KEY', '').strip()
SITE_URL = "https://rkskqdl-a11y.github.io/coupang-sale-shuttle"

def generate_ai_content(product_name):
    """ğŸ’ ì˜ì¡´ì„± ì—ëŸ¬ ì—†ì´ requestsë¡œ AI ë¦¬ë·° ìƒì„± (1,000ì ì¥ë¬¸)"""
    if not GEMINI_KEY: return "ë¶„ì„ ë°ì´í„° ì¤€ë¹„ ì¤‘"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_KEY}"
    prompt = f"ìƒí’ˆ '{product_name}'ì— ëŒ€í•´ ì „ë¬¸ì ì¸ ë¶„ì„ ì¹¼ëŸ¼ì„ 1,000ì ì´ìƒ ì‘ì„±í•´ì¤˜. <h3> í™œìš©, HTMLë§Œ ì‚¬ìš©, 'í•´ìš”ì²´', 'í• ì¸' ì–¸ê¸‰ ê¸ˆì§€."
    try:
        res = requests.post(url, json={"contents": [{"parts": [{"text": prompt}]}]}, timeout=60)
        return res.json()['candidates'][0]['content']['parts'][0]['text'].replace("\n", "<br>")
    except: return f"<h3>ğŸ” ì œí’ˆ ë¶„ì„</h3>{product_name}ì€ í’ˆì§ˆê³¼ ì„±ëŠ¥ì´ ê²€ì¦ëœ ëª¨ë¸ì…ë‹ˆë‹¤."

def fetch_data(keyword, page):
    """ğŸ’ [í•µì‹¬] ì¿ íŒ¡ API ì¸ì¦ì„ 100% ì„±ê³µì‹œí‚¤ëŠ” ì—„ê²©í•œ ì¿¼ë¦¬ ìƒì„±"""
    DOMAIN = "https://api-gateway.coupang.com"
    path = "/v2/providers/affiliate_open_api/apis/openapi/v1/products/search"
    
    # ğŸ’ ì¤‘ìš”: íŒŒë¼ë¯¸í„°ëŠ” ë°˜ë“œì‹œ ì•ŒíŒŒë²³ ìˆœì„œ(keyword -> limit -> page)ì—¬ì•¼ í•©ë‹ˆë‹¤.
    query_string = f"keyword={quote(keyword)}&limit=20&page={page}"
    
    # ì„œëª… ìƒì„± (datetime + method + path + query_string)
    datetime_gmt = time.strftime('%y%m%dT%H%M%SZ', time.gmtime())
    message = datetime_gmt + "GET" + path + query_string
    signature = hmac.new(bytes(SECRET_KEY, 'utf-8'), msg=bytes(message, 'utf-8'), digestmod=hashlib.sha256).hexdigest()
    
    headers = {
        "Authorization": f"CEA algorithm=HmacSHA256, access-key={ACCESS_KEY}, signed-date={datetime_gmt}, signature={signature}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get(f"{DOMAIN}{path}?{query_string}", headers=headers, timeout=15)
        if response.status_code == 200:
            return response.json().get('data', {}).get('productData', [])
        else:
            # ğŸ’ ì´ì œ ë¡œê·¸ì—ì„œ ì™œ 0ê°œì¸ì§€ (401, 403 ë“±) ìˆ«ìë¡œ ë°”ë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤.
            print(f"   âš ï¸ ì¿ íŒ¡ ì„œë²„ ì‘ë‹µ ì‹¤íŒ¨: {response.status_code} | {response.text[:50]}")
            return []
    exceptException as e:
        print(f"   âš ï¸ ì—°ê²° ì˜¤ë¥˜: {e}")
        return []

def get_title_from_html(filepath):
    """ğŸ’ ì¸ë±ìŠ¤ ìƒì„±ì„ ìœ„í•œ ì œëª© ì¶”ì¶œ í•¨ìˆ˜"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            match = re.search(r'<title>(.*?)</title>', content)
            if match: return match.group(1).replace(" ë¦¬ë·°", "")
    except: pass
    return "ì¶”ì²œ ìƒí’ˆ"

def main():
    os.makedirs("posts", exist_ok=True)
    
    # ğŸ’ ì „ í’ˆëª© ìˆ˜ì§‘ì„ ìœ„í•œ ê´‘ëŒ€ì—­ ì”¨ì•— í‚¤ì›Œë“œ
    seeds = ["ì‚¼ì„±", "ì—˜ì§€", "ê°€ì „", "ë…¸íŠ¸ë¶", "ìš´ë™í™”", "ìƒ´í‘¸", "ë¹„íƒ€ë¯¼", "ë¬¼í‹°ìŠˆ", "ê¸°ì €ê·€", "ì–‘ë§"]
    target = random.choice(seeds)
    
    existing_ids = {f.split('_')[-1].replace('.html', '') for f in os.listdir("posts") if '_' in f}
    success_count, max_target = 0, 10
    
    print(f"ğŸ•µï¸ í˜„ì¬ {len(existing_ids)}ê°œ ë…¸ì¶œ ì¤‘. '{target}' ê¸°ë°˜ ì €ì¸ë§ ìˆ˜ìƒ‰ ì‹œì‘!")

    # ğŸ’ 1í˜ì´ì§€ë¶€í„° ì°¨ë¡€ëŒ€ë¡œ! ì¤‘ë³µì´ë©´ ë‹¤ìŒ í˜ì´ì§€ë¡œ!
    for page in range(1, 31): 
        if success_count >= max_target: break
        
        print(f"ğŸ” [í˜ì´ì§€ {page}] ë¶„ì„ ì¤‘...")
        products = fetch_data(target, page)
        
        if not products: continue # ì—ëŸ¬ ë¡œê·¸ëŠ” ìœ„ì—ì„œ ì°í˜

        for item in products:
            p_id = str(item['productId'])
            if p_id in existing_ids: continue # ì¤‘ë³µ íŒ¨ìŠ¤

            p_name = item['productName']
            print(f"   âœ¨ ë°œê²¬! [{success_count+1}/10] {p_name[:20]}...")
            
            ai_content = generate_ai_content(p_name)
            img, price = item['productImage'].split('?')[0], format(item['productPrice'], ',')
            
            filename = f"posts/{datetime.now().strftime('%Y%m%d')}_{p_id}.html"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(f"<!DOCTYPE html><html lang='ko'><head><meta charset='UTF-8'><title>{p_name} ë¦¬ë·°</title><style>body{{font-family:sans-serif; background:#f8f9fa; padding:20px; color:#333; line-height:2.2;}} .card{{max-width:750px; margin:auto; background:white; padding:50px; border-radius:30px; box-shadow:0 20px 50px rgba(0,0,0,0.05);}} h3{{color:#e44d26; margin-top:40px; border-left:6px solid #e44d26; padding-left:20px;}} img{{width:100%; border-radius:20px; margin:30px 0;}} .p-val{{font-size:2.5rem; color:#e44d26; font-weight:bold; text-align:center;}} .buy-btn{{display:block; background:#e44d26; color:white; text-align:center; padding:25px; text-decoration:none; border-radius:60px; font-weight:bold; font-size:1.3rem;}}</style></head><body><div class='card'><h2>{p_name}</h2><img src='{img}'><div class='content'>{ai_content}</div><div class='p-val'>{price}ì›</div><a href='{item['productUrl']}' class='buy-btn'>ğŸ›ï¸ ìƒì„¸ ì •ë³´ í™•ì¸í•˜ê¸°</a></div></body></html>")
            
            existing_ids.add(p_id)
            success_count += 1
            time.sleep(30)
            if success_count >= max_target: break

    # ğŸ’ [SEO ë™ê¸°í™”] êµ¬ê¸€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì˜¤ë¥˜ í•´ê²°
    files = sorted([f for f in os.listdir("posts") if f.endswith(".html")], reverse=True)
    now_iso = datetime.now().strftime("%Y-%m-%d")
    
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(f"<!DOCTYPE html><html lang='ko'><head><meta charset='UTF-8'><title>ì¿ íŒ¡ í•«ë”œ ì…”í‹€</title><style>body{{font-family:sans-serif; background:#f0f2f5; padding:20px;}} .grid{{display:grid; grid-template-columns:repeat(auto-fill, minmax(300px, 1fr)); gap:20px;}} .card{{background:white; padding:25px; border-radius:20px; text-decoration:none; color:#333; box-shadow:0 5px 15px rgba(0,0,0,0.05);}}</style></head><body><h1 style='text-align:center;'>ğŸš€ ì‹¤ì‹œê°„ ì¿ íŒ¡ ì „ìˆ˜ ì¡°ì‚¬ ë§¤ê±°ì§„</h1><div class='grid'>")
        for file in files[:100]:
            title = get_title_from_html(f"posts/{file}")
            f.write(f"<a class='card' href='posts/{file}'><div>{title}</div><div style='color:#e44d26; font-weight:bold; margin-top:15px;'>ì¹¼ëŸ¼ ì½ê¸° ></div></a>")
        f.write("</div></body></html>")

    with open("sitemap.xml", "w", encoding="utf-8") as f:
        # ğŸ’ xmlns ì†ì„±ì„ ì •í™•íˆ ì¶”ê°€í•˜ì—¬ êµ¬ê¸€ ê²½ê³ ë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤.
        f.write('<?xml version="1.0" encoding="UTF-8"?>\n<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n')
        f.write(f'  <url><loc>{SITE_URL}/</loc><lastmod>{now_iso}</lastmod><priority>1.0</priority></url>\n')
        for file in files:
            f.write(f'  <url><loc>{SITE_URL}/posts/{file}</loc><lastmod>{now_iso}</lastmod></url>\n')
        f.write('</urlset>')

    with open("robots.txt", "w", encoding="utf-8") as f:
        f.write(f"User-agent: *\nAllow: /\nSitemap: {SITE_URL}/sitemap.xml")

    print(f"ğŸ ì‘ì—… ì™„ë£Œ! ì´ {len(files)}ê°œ ë…¸ì¶œ ì¤‘. (ì‹ ê·œ ë°œí–‰: {success_count}ê°œ)")

if __name__ == "__main__":
    main()
